{
  
    
        "post0": {
            "title": "Great Expectation First Take",
            "content": "Great Expectation First Take . What is cls? Similar to self but cls is used when the method is a class method . What is @DocInherit? It overrides function’s __get__ method with one that will replace the local docstring with the docstring from its parent. It is defined in Dataset.uitl. . Basically, we need to edit the great_expectations.yml file and push this to the repo and the pipeline or the agent will be able to execute the jobs. Below are the content of the great_expectation.yml. . . The datasources is to define the data source and extract the batch of the data for processing. In the demo, I used files (csv files) in the files system so the class_name is PandasDataset. It works for more than csv file. Parquet, xls, xlsx, json and other common extensions are recognized. However, all batch_kwargs will be extracted out and will be used for creating pandas dataframe for later use (for the cases of local files). . . Config_variables_file_path is the directory for saving config_variables.yml which holds sensitive secrets such as database credential. Plugins is to add more features or for more customizations. . . These stores are directories to store different outcomes or parameters. Expectation_store stores the json files for different suites. The json files explain what expectation types were used. Expectation types are like metrics before. For example, max and min values. And we can set these values and apply to only specific columns. Validation stores validation results. Like how many expectations are tested, how many of them failed and what are the unexpected values in the expectations. Validation results are in json format. Checkpoints are the previous data. Mostly should be the good ones so that we can use them to validate new data. . . Data docs are the html file of the expectation suite results, they are the visualizations of the outcome. There is home page for them and can monitor different projects or suites. Home page is like below. . . Metrics and tests are expectations in this library. The collection of them is an expectation suite. See below. . From my own experiences, it does not work like user drop off a file then the output would come out. It went through some python codes in notebook. It would be better if modifying the pipeline to operate those python modules once the target datafile is pushed to the repo. I will upload the notebook later. .",
            "url": "https://itsming97.github.io/how-to-be-rengoku-diary/2021/08/04/Great-Expectation-First-Take.html",
            "relUrl": "/2021/08/04/Great-Expectation-First-Take.html",
            "date": " • Aug 4, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Soda Second Take",
            "content": "Soda.io Second Take . Today I continued to set up my soda sql command line interface. . Many different tryouts: . I thought that I didn’t have the postgres database. I checked them and I do have them. By calling . psql I was able to run SQL command lines on windows powershell. . | I re-installed soda-sql-postgresql. There were two errors that kept the installation being successful. First one is the installation of psycopg2-binary. I tried manually installed the library by using pip and re-installed soda sql but it still had the same error. Then I found the second error was about the version of the Visual Studio and the C++ compilers and libraries, etc. So I installed the latest visual studio build tools and install the C++ kit. After all, the soda sql was installed successfully with a couple warnings but no errors. However, the programmatic access still didn’t go through. . | After making sure that all dependencies or other needed packages were installed properly, I started to look at the traceback of the errors. But I don’t know how to debug them. . | After trying multiple solutions but not making it run, I put soda aside and started to look into Great Expectation. I do not have much details for now. I would keep looking at its codes and documentations after dinner. I would include this part into my tomorrow’s blog. .",
            "url": "https://itsming97.github.io/how-to-be-rengoku-diary/2021/08/03/Soda-Second-Take.html",
            "relUrl": "/2021/08/03/Soda-Second-Take.html",
            "date": " • Aug 3, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Soda First Take",
            "content": "Soda First Take . Programmatic access: Soda SQL . Web-app access: Soda Cloud . Soda SQL: . Connect data source . Seems to be only able to connect with database (not a single file) . | Users need to edit warehouse.yml and env_vars.yml manually (one is database access details like port, one is credentials) . Different yaml files for different schema databases | | | Must do a first scan (similar to our data registration) . Scan yaml needs to define table, metrics to be used, test to be operated or optionally the columns in the table that will be tested . Different scan yaml files for different datasets within the same database | | | Then we can apply default metrics or user-defined metrics to columns. (user-defined metrics are more like SQL queries). It also needs to submit a scan yaml file to do the jobs. . | I tried to followed the instructions to use soda SQL, but I ran into errors. I got a couple warnings when I did “pip install soda-sql-postgresql” but it still went through. When I tried to use “soda create” to create the data warehouse yaml file. It failed. So was the env_var yaml file. Therefore, I manually created them. Then run “soda analyze” but it still couldn’t go through. I think it has to do with the yaml file parser. . After failed to use my own dataset. I tried to use their tutorial dataset which was containerized. And it still wouldn’t work for me. No containers were running with no errors. . . . Soda Cloud: . They have a clean UI. However, I was not able to connect to their tutorial database neither. . | . | According to the documentation, users can edit data source, edit tests, and define metrics when creating new monitors. . | Metrics: . I can find their files and view them in Pycharm or Notepad++ but I didn’t understand them. The hierarchical architecture about different modules is a bit complex for me. It would take me a while to understand them. . .",
            "url": "https://itsming97.github.io/how-to-be-rengoku-diary/2021/08/02/Soda-First-Take.html",
            "relUrl": "/2021/08/02/Soda-First-Take.html",
            "date": " • Aug 2, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "First",
            "content": "My first blog . Monday: . I set up the spark environment on my local device. . I first installed the Java 8. Many people reported that later Java version like 9 or 10 are not compatible with spark. . | Then I installed Python (the latest version) on my machine. Before installing python, I mostly ran python on Anaconda environment using jupyter notebook, and I ran a few py files using Spyder. I am not very sure about the differences, but before downloading python, I ran command line “python –version” on windows prompt and there was no output. There was an important step during the python installation is to add python to PATH which we can find and edit the system environment variables. . | Then I installed spark from apache spark official website, also the latest version. I learned that checking the software file checksum is a good way to verify the integrity of the download before installing. . | Then I added winutils.exe file for the underlying Hadoop version to my desired folder. . | Then I configured my environment variables. Mainly I added the spark, Hadoop, and java to PATH as I did to python during installation. . | Lastly, I launched spark. By calling spark-shell, I was able to run spark with scala. By calling pyspark, I was able to run spark with python. . | Two bugs took me most of the time. One is that “WARN ProcfsMetricsGetter:Exception when trying to compute pagesize” error, I didn’t solve this problem as I found that this is a minor bug that does not affect the performance and it should be just some metric issues. The second bug occurred when I tried to use pyspark. It is a bug involves JavaError, Python and py4j keywords. I tried a couple methods including downloading py4j, editing the environment variables on PATH, calling different files to launch Python, managing app execution aliases, etc. I solved it by setting the environment variable (PYSPARK_PYTHON = /path/python) on window prompt before calling the pyspark file. (However, at the moment I am writing this blog. It does not work. I will try to figure out tomorrow.) Anyway, they all worked on Monday. . | . Tuesday: . Basically I didn’t do anything because the repair took me whole day. . Wednesday: . I installed Journal. I followed the instruction although I could not understand it completely. What I learned the most from the process is having a better idea about what docker is and how to use docker. I successfully downloaded the Journal image and run the container. However, I don’t know how to use the container. I still don’t know how to run the Journal command line. . | I also implemented fastpages for the my blog. I didn’t change much content and interface of the blog and add additional designs to it yet as docker took me most of the time. . | .",
            "url": "https://itsming97.github.io/how-to-be-rengoku-diary/2021/07/28/first.html",
            "relUrl": "/2021/07/28/first.html",
            "date": " • Jul 28, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://itsming97.github.io/how-to-be-rengoku-diary/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://itsming97.github.io/how-to-be-rengoku-diary/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}